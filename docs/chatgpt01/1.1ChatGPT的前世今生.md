# ChatGPT的前世今生

# 发展历史

**·** 2015年——在2015年12月11日创立 OpenAI在美国成立 Y Combinator的 Sam Altman 和 Elon Musk 作为 OpenAI 的首席联合创始人

· 2016年——推出用于开发和比较学习强化算法的工具包 OpenAI Gym 与 Universe 软件平台

· 2018年——Elon Musk离开OpenAI，Sam Altman成为Open AI的 CEO 发布通用NLP模型 GPT，含1.17亿参数

· 2019年——微软向OpenAI投资10亿美元发布GPT-2，含15亿参数

· 2020年——OpenAI发布GPT-3，含1750亿参数，微软获得了GPT-3的独家授权

· 2021年——发布了CLIP，匹配图像和文本的预训练大模型，发布了DALL·E，文字生成图像 AI 系统

· 2022年——发布DALL·E 2。在GPT-3.5的基础上推出ChatGPT ，强化了人工智能的语言对话能力

· 2023年——ChatGPT 全面出圈，微软宣布旗下所有产品全线整合 ChatGPT，并宣布将向 OpenAI 追加投资数十亿美元

# 商业模式

## **01.OPenAI的产品**

虽然AI的应用我们听过很多，不过现阶段较广泛应用的 AI 主要三个大类：

1、决策类人工智能—— 常见于金融机构，比如某笔贷款该不该发、某笔转账是否涉及洗钱该不该放行等，机器会给出决策。

2、视觉人工智能—— 人脸识别、文字图片的识别、路况识别等，会用于办公、安防、自动驾驶等领域。

3、语音及语义人工智能——如机器识别、理解、输出自然语言。

目前OpenAI大火的ChatGPT主要就是在语义人工智能方向。根据官网介绍，目前OpenAI主要有如下几个产品：

1、ChatGPT

2、DALL·E 2

3、Whisper

CLIP（Constrastive Language-Image Pre-training）是一个基于对比图片-文本学习的跨模态预训练模型，通过自然语言的监督学习来有效理解视觉概念，用户只需要提供要识别的视觉类别标签，CLIP 就能完成视觉分类任务。

而OpenA推出的DALL·E 2就是基于CLIP而诞生的文字生成图片AI系统。

<img src=".\images\\image-20230227121521660.png" alt="image-20230227121521660" style="zoom:80%;" />

DALL·E 2不但可以根据文字创造生成图片，还可以通过生成并且创造图片外的构图，就像这样还能通过原图的基础上，创造出各种风格。

<img src=".\images\\image-20230227121546056.png" alt="image-20230227121546056" style="zoom:80%;" />

他们家另一个产品 Whisper，则是一个自动语音识别（ASR）系统，使用从网络收集的68万小时多语言和多任务监督数据进行训练。

<img src=".\images\\image-20230227121607578.png">

此外，它允许以多种语言转录，以及从这些语言翻译成英语。

## **02 ChatGPT的应用场景**

ChatGPT 是“Chat Generative Pre-trained Transformer”的简称，是由 OpenAI 于 2022 年 11 月推出的一款聊天机器人（AI Chatbot）。

它是基于GPT-3.5 （GPT-3 的改进版）模型的变体。ChatGPT 可以在对话中根据上下文形成类似人类的文本响应，与其他使用预定义的响应或规则生成文本的聊天机器人不同，ChatGPT 可以根据接收到的输入生成响应，从而生成更自然、更多样化的响应。

ChatGPT不仅是聊天机器人，还能进行撰写邮件、文案、代码等任务。从 2022 年 11 月上线以来，在 ChatGPT上的累积用户已经达到 1 亿。

在“搜索”方面，对谷歌来说ChatGPT就是目前面临的最大挑战。

谷歌邮箱的创始人 Paul Buchheit 甚至发推特称“谷歌距离全面被颠覆可能只有一到两年时间”

<img src=".\images\\image-20230227121628411.png" alt="image-20230227121628411" style="zoom:80%;" />

而且身边不少玩ChatGPT的朋友都开始把它当做搜索引擎来使用，用来查阅各种资料，甚至用来查代码bug。

这就是为什么谷歌为什么会如此紧急召回了两位已经“退休”的创始人，还匆匆忙忙地发布了自家的类ChatGPT产品——Bard。

<img src=".\images\\image-20230227121640452.png" alt="image-20230227121640452" style="zoom:80%;" />

可惜的是，再Bard刚发布就“翻车”了，回答的答案很快就被网友指出了事实性错误，谷歌的股价大跌10%。

虽然ChatGPT也会经常“一本正经地胡说八道”，但这种非现场录制出来的演示结果都出现错误，很难不让市场感觉到谷歌的匆忙应对。

而对于ChatGPT目前能否颠覆搜索引擎，在***新浪AI Lab担任资深算法专家的「张俊林」***在知乎上的回答给了我们一个参考的方向，*目前形态ChatGPT还不能替代搜索引擎*，主要因为：

1、目前ChatGPT的回答还有很多事实性的错误，需要用户自己去判断内容的真伪；

2、GPT大模型基础上再进一步增加标注数据进行训练，新知识也在不断出现，不断训练的时间成本与金钱成本都太高；

3、搜索引擎的访问量是巨大的，目前ChatGPT可能会无法承受这训练成本；

然后展望未来以后搜索引擎可能会才用「双引擎」模式——***以ChatGPT搜索为主，传统搜索为辅***。大意就是：

1、搜索首页第一个显示的就是ChatGPT生成的结果，并显示引用的链接用来给用户判断信息的真伪。

2、剩余的结果就通过传统搜索页去展示。

3、随着ChatGPT的回答准确率的提升以及训练成本的下降，最终慢慢过度到只有ChatGPT的最终形态。

而谷歌的搜索最大竞争对手微软，他们的自家搜索Bing 接入ChatGPT后改名叫 “new Bing”（也是够牛逼的

），也已经在干类似的事情，你说谷歌怎么能不慌？

<img src=".\images\\image-20230227121734365.png" alt="image-20230227121734365" style="zoom:80%;" />

## **03 ChatGPT的原理**

先简单解释个小概念

***RLHF（Reinforce Learning with Human Feedback）***

***简单说就是利用人类反馈信号直接优化语言模型，通过人类的反馈去修正Ai自己的错误，最终Ai生成的结果就会越来越准确***

ChatGPT 采用监督学习+奖励模型进行语言模型训练。ChatGPT 使用来自人类反馈的强化学习 (RLHF) 来训练该模型。

首先使用监督微调训练了一个初始模型：人类 AI 训练员提供对话，他们在对话中扮演双方——用户和 AI 助手。

其次，ChatGPT 让标记者可以访问模型编写的建议，以帮助他们撰写回复。

最后，ChatGPT 将这个新的对话数据集与原有数据集混合，将其转换为对话格式。

具体来看，主要包括三个步骤：

1）***第一阶段：训练监督策略模型***。在 ChatGPT 模型的训练过程中，需要标记者的参与监督过程。首先，ChatGPT 会从问题数据集中随机抽取若干问题并向模型解释强化学习机制，其次标记者通过给予特定奖励或惩罚引导 AI 行为，最后通过监督学习将这一条数据用于微调 GPT3.5 模型。

2）***第二阶段：训练奖励模型***。*这一阶段的主要目标，在于借助标记者的人工标注*，训练出合意的奖励模型，为监督策略建立评价标准。训练奖励模型的过程同样可以分为三步：1、抽样出一个问题及其对应的几个模型输出结果；2、标记员将这几个结果按质量排序；3、将排序后的这套数据结果用于训练奖励模型。

3）***第三阶段：采用近端策略优化进行强化学习。***近端策略优化（Proximal Policy Optimization）是一种强化学习算法，核心思路在于将 Policy Gradient 中 On-policy 的训练过程转化为Off-policy，即将在线学习转化为离线学习。具体来说，也就是先通过监督学习策略生成 PPO模型，经过奖励机制反馈最优结果后，再将结果用于优化和迭代原有的 PPO 模型参数。

往复多次第二阶段和第三阶段，从而得到参数质量越来越高的 ChatGPT 模型。

<img src=".\images\\image-20230227121812566.png">

**04**

**ChatGPT的核心优势**

***ChatGPT 使用了单一大模型，积累了强大的底层通用能力。***模型体量的增大，带来的最直接变化，在于 AI 模型通用能力的跨越式提升。

传统的 AI 训练方法，大多以单一知识领域的应用为目标，主要使用特定领域有标注的数据进行模型训练，模型通用性差，如果更换使用场景，往往需要进行重新训练。

而大模型的训练：

1、一是能使用的数据来源更加广泛，可用数据量更大；

2、对标注要求更低，只需要对数据进行微调甚至不调就可以用于训练；

3、输出的能力更加泛化通用，在语义理解、逻辑推理、文本表达等方面能力更出众；

***AI 大模型与人类学习的方式相似***，人类则是先学习如何学习，再构建听说读写能力，最后再开始学习不同知识，AI也类似的先完成通用能力的积累，再将学习能力运用到其他特定领域，有了这个能力后，只需要对AI投喂垂直领域的数据，就可以训练成想要的应用场景。

<img src=".\images\\image-20230227121831575.png">

***从大模型自身的发展过程来看，参数量的变化是一个非常值得关注的指标。从最早的 ResNet、Inception 等模型，到如今的 GPT，模型参数量不断增长。***

***2018年前后OpenAI 先后推出 Transformer 和 GPT-1 模型，参数量来到 1 亿级别。***

***随后谷歌提出 3 亿参数的 BERT 模型，参数量再次增长。***

***2019、2020 年，OpenAI 加速追赶，陆续迭代出 GPT-2、GPT-3 模型，参数量分别为15 亿、1750 亿，实现模型体量质的飞跃。***

可见算力也是AI训练很重要的因素，而微软对OpenAI的投资，也算是很大一部分的助力。除了资金支持外，还能借助微软Azure的基础算力设置，为 ChatGPT的训练提供足够的支持。

## **05OpenAI的收费方式**

目前，OpenAI 提供 GPT-3、 Codex 以及 DALL·E 的 API 数据接口，分别执行用户自然语言任务、自然语言转换为代码的任务以及创建和编辑图像的任务。

API 接口根据类型不同以流量收费，比如图像模型以分辨率分类按张数收费，语言模型则以基于的子模型型号按字符数收费。

<img src=".\images\\image-20230227121901160.png">

OpenAI 正尝试拓展自身盈利模式，2023 年 1 月试点推出订阅制 ChatGPT Plus，收取每月 20 美元的会员费以得到各类优先服务。

<img src=".\images\\image-20230227121938363.png">